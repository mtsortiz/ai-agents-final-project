# La Delicia RAG â€“ Bruno, el Mozo Virtual

Sistema conversacional con **LangGraph** + **RAG** que actÃºa como mozo virtual (â€œBrunoâ€) para el restaurante *La Delicia*.  
El agente consulta una base de conocimiento (Chroma) y, al cerrar la conversaciÃ³n, registra un informe en **Notion**.

## âœ¨ Funcionalidades
- **RAG** con `Chroma` + embeddings de Google (`models/text-embedding-004`).
- **Agentes con LangGraph**:
  - `experto_menu`: responde preguntas sobre menÃº/horarios usando el retriever.
  - `capitan_pedidos`: genera un resumen y lo **guarda en Notion**.
- **Tools**:
  - `consultar_menu_y_horarios` (retriever)
  - `off_topic_tool` (redirecciÃ³n si la consulta no es del restaurante)
  - `guardar_informe_en_notion` (persistencia externa)
- **CLI interactiva**.

---

## ğŸ§± Requisitos
- Python 3.10+ (recomendado 3.11 o 3.12)
- Cuenta/API Key de **Google Generative AI (Gemini)**
- Base de datos en **Notion** (con `NOTION_API_KEY` y `NOTION_DATABASE_ID`)
- (Opcional para la rÃºbrica) Cuenta en **LangSmith** para tracing

---

## âš™ï¸ InstalaciÃ³n

```bash
# 1) Clonar el repo
git clone https://github.com/mtsortiz/ai-agents-final-project.git
cd ai-agents-final-project/


# 2) Crear entorno virtual
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate

# 3) Instalar dependencias
pip install -r requirements.txt
```

---

## ğŸ” Variables de entorno

Crear un archivo **.env** en la raÃ­z del proyecto:

```env
# Google Gemini
GEMINI_API_KEY=tu_api_key_de_gemini

# Notion
NOTION_API_KEY=tu_api_key_de_notion
NOTION_DATABASE_ID=tu_database_id

# (Opcional pero requerido por la rÃºbrica) LangSmith
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=tu_api_key_de_langsmith
LANGCHAIN_PROJECT=la-delicia
```


---

## â–¶ï¸ EjecuciÃ³n

```bash
python -m src.main
```

Flujo tÃ­pico:
1. EscribÃ­ consultas como â€œholaâ€, â€œÂ¿tenÃ©s platos con arroz?â€, etc.
2. Para finalizar: **â€œgraciasâ€, â€œchauâ€, â€œsalirâ€** (el router derivarÃ¡ el cierre al CapitÃ¡n y se guardarÃ¡ en Notion).

---

## ğŸ§  CÃ³mo funciona (resumen tÃ©cnico)

- **Documentos**: el menÃº y la info del negocio se cargan como `Document` y se partean con `RecursiveCharacterTextSplitter`.
- **Vectorstore**: se indexa en **Chroma** (persistente en `.chroma/la-delicia`).
- **Retriever**: `vectorstore.as_retriever(search_kwargs={"k": 3})`.
  - `k` es cuÃ¡ntos *chunks* mÃ¡s similares trae por consulta (mÃ¡s `k` = mÃ¡s contexto, pero tambiÃ©n mÃ¡s ruido/costo).
- **LangGraph**:
  - Router â†’ deriva a `experto_menu` o `capitan_pedidos` segÃºn el Ãºltimo mensaje humano (despedida).
  - `experto_menu` solo puede llamar `consultar_menu_y_horarios` u `off_topic_tool`.
  - `capitan_pedidos` solo puede llamar `guardar_informe_en_notion`.

---

## ğŸ§© Estructura (sugerida)

```
.
â”œâ”€ src/
â”‚  â””â”€ main.py
â”œâ”€ .chroma/                # (persistencia local de Chroma)
â”œâ”€ .env
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## âœ… Estado del proyecto vs. Requisitos

- [x] **LangGraph con 2 agentes** (`experto_menu`, `capitan_pedidos`)
- [x] **RAG** con Chroma + Embeddings
- [x] **Persistencia en Notion** (tool `guardar_informe_en_notion`)
- [x] **Observabilidad (LangSmith)**: *Falta activarlo y adjuntar el link de Project Run en la documentaciÃ³n*
- [ ] **Cierre 100% por grafo**: *Asegurar que la despedida vaya por router â†’ `capitan_pedidos` y no llamar la tool Notion desde el loop principal*
- [ ] **Edge de retorno del CapitÃ¡n**: *Verificar que exista `graph.add_edge("tools", "capitan_pedidos")` para completar el ciclo tras la tool*

### QuÃ© falta para completar la rÃºbrica
1. **Activar LangSmith** (no desactivar tracing).  
   - Mantener en `.env`:  
     ```
     LANGCHAIN_TRACING_V2=true
     LANGCHAIN_API_KEY=...
     LANGCHAIN_PROJECT=la-delicia
     ```
   - Correr una sesiÃ³n real y **pegar el link de la Project Run** aquÃ­ en el README.
2. **Cierre por grafo** (no manual):  
   - Quitar el bypass que llama Notion directo en `main()` para despedidas, y dejar que el **router** derive a `capitan_pedidos`.
3. **Edge del CapitÃ¡n**:  
   - Asegurar en `build_graph(...)`:
     ```python
     graph.add_edge("tools", "capitan_pedidos")
     ```

---

## ğŸ§ª Consejos de prueba

- Preguntas ejemplo:
  - â€œÂ¿TenÃ©s platos con arroz?â€ â†’ deberÃ­a citar el *Risotto de Hongos*.
  - â€œÂ¿Horario de cena?â€ â†’ deberÃ­a recuperar los horarios del documento.
  - â€œÂ¿QuÃ© tal Messi?â€ â†’ deberÃ­a activar `off_topic_tool`.
- Cierre:
  - Escribir â€œgraciasâ€ â†’ router â†’ `capitan_pedidos` â†’ tool de Notion â†’ despedida.

---

## ğŸ§· Troubleshooting rÃ¡pido

- **`InvalidArgument: GenerateContentRequest.contents is not specified`**  
  Asegurate de que **siempre** haya al menos un `HumanMessage` antes de invocar el LLM. En el cierre, dejÃ¡ que el router envÃ­e al CapitÃ¡n (que agrega un `HumanMessage` propio).
- **Bucle infinito / Recursion limit**  
  LimitÃ¡ las tools por nodo (ya estÃ¡ hecho) y aÃ±adÃ­ los edges de regreso correctos.  
- **No se guarda en Notion**  
  Revisa `NOTION_API_KEY` y `NOTION_DATABASE_ID`. El DB debe tener propiedades: `Consulta` (title), `Resumen` (rich_text), `Fecha` (date).

---

## ğŸ“œ Licencia
MIT (o la que prefieran)
